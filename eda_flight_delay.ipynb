{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column additions\n",
    "## elevation change\n",
    "## latitude - longitude change\n",
    "## continent - continent code\n",
    "## country to country code\n",
    "## airport to airport code\n",
    "## flighttime\n",
    "## average speed flighttime/distance\n",
    "## airport to airport coded\n",
    "## company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = (11, 7)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna \n",
    "\n",
    "# Feel free to add all the libraries you need\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_17592\\2418746488.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['iata']=df2['iata'].replace('BER','SXF')\n"
     ]
    }
   ],
   "source": [
    "import airportsdata\n",
    "airports = airportsdata.load()\n",
    "\n",
    "df1 = pd.DataFrame(airports).T.reset_index()\n",
    "removeindexcolumn = df1.columns.tolist()\n",
    "removeindexcolumn.remove('index')\n",
    "df2 = df1[removeindexcolumn]\n",
    "df2['iata'].str.contains('BER')\n",
    "df2['iata']=df2['iata'].replace('BER','SXF')\n",
    "df2[df2['iata']=='SXF']\n",
    "df2.to_csv('data/airportdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flightdata = pd.read_csv('data/Train.csv')\n",
    "df_airportdata = pd.read_csv('data/airportdata.csv')\n",
    "\n",
    "df_flightdata['STA'] = pd.to_datetime(df_flightdata['STA'], format='%Y-%m-%d %H.%M.%S')\n",
    "df_flightdata['STD'] = pd.to_datetime(df_flightdata['STD'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_flightdata['DATOP'] = pd.to_datetime(df_flightdata['DATOP'], format='%Y-%m-%d')\n",
    "df_flightdata['target'].astype('float')\n",
    "df_airportdata['elevation'] = df_airportdata['elevation'].astype('float')\n",
    "df_airportdata['lat'] = df_airportdata['lat'].astype(float)\n",
    "df_airportdata['lon'] = df_airportdata['lon'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>TU 0712</td>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12:55:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>TU 0757</td>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16:55:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>TU 0214</td>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06:45:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0480</td>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17:00:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0338</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15:50:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMU</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID      DATOP     FLTID DEPSTN ARRSTN                 STD   \n",
       "0  train_id_0 2016-01-03  TU 0712     CMN    TUN 2016-01-03 10:30:00  \\\n",
       "1  train_id_1 2016-01-13  TU 0757     MXP    TUN 2016-01-13 15:05:00   \n",
       "2  train_id_2 2016-01-16  TU 0214     TUN    IST 2016-01-16 04:10:00   \n",
       "3  train_id_3 2016-01-17  TU 0480     DJE    NTE 2016-01-17 14:10:00   \n",
       "4  train_id_4 2016-01-17  TU 0338     TUN    ALG 2016-01-17 14:30:00   \n",
       "\n",
       "                  STA STATUS         AC  target  \n",
       "0 2016-01-03 12:55:00    ATA  TU 32AIMN   260.0  \n",
       "1 2016-01-13 16:55:00    ATA  TU 31BIMO    20.0  \n",
       "2 2016-01-16 06:45:00    ATA  TU 32AIMN     0.0  \n",
       "3 2016-01-17 17:00:00    ATA  TU 736IOK     0.0  \n",
       "4 2016-01-17 15:50:00    ATA  TU 320IMU    22.0  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flightdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depart = df_airportdata[['iata', 'country', 'elevation', 'lat', 'lon']]\n",
    "df_arrive = df_airportdata[['iata', 'country', 'elevation', 'lat', 'lon']]\n",
    "\n",
    "depart_column_names = df_depart.columns.tolist() \n",
    "new_depart_names = []\n",
    "for i in depart_column_names:\n",
    "    new_depart_names.append(i + '_depart')\n",
    "df_depart= df_depart.set_axis(new_depart_names, axis='columns')\n",
    "\n",
    "arrive_column_names = df_arrive.columns.tolist() \n",
    "new_arrive_names = []\n",
    "for i in arrive_column_names:\n",
    "    new_arrive_names.append(i + '_arrive')\n",
    "df_arrive = df_arrive.set_axis(new_arrive_names, axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flightdata.rename(columns = {'ARRSTN':'iata_arrive'}, inplace = True)\n",
    "df_flightdata.rename(columns = {'DEPSTN':'iata_depart'}, inplace = True)\n",
    "df_flightdata1 = df_flightdata.merge(df_arrive, on='iata_arrive', how= 'left')\n",
    "df = df_flightdata1.merge(df_depart, on='iata_depart', how= 'left')\n",
    "df.rename(columns = {'iata_arrive':'ARRSTN'}, inplace = True)\n",
    "df.rename(columns = {'iata_depart':'DEPSTN'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "      <th>target</th>\n",
       "      <th>country_arrive</th>\n",
       "      <th>elevation_arrive</th>\n",
       "      <th>lat_arrive</th>\n",
       "      <th>lon_arrive</th>\n",
       "      <th>country_depart</th>\n",
       "      <th>elevation_depart</th>\n",
       "      <th>lat_depart</th>\n",
       "      <th>lon_depart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>TU 0712</td>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12:55:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>260.0</td>\n",
       "      <td>TN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.851002</td>\n",
       "      <td>10.22720</td>\n",
       "      <td>MA</td>\n",
       "      <td>656.0</td>\n",
       "      <td>33.367500</td>\n",
       "      <td>-7.58997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>TU 0757</td>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16:55:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "      <td>20.0</td>\n",
       "      <td>TN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.851002</td>\n",
       "      <td>10.22720</td>\n",
       "      <td>IT</td>\n",
       "      <td>768.0</td>\n",
       "      <td>45.630600</td>\n",
       "      <td>8.72811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>TU 0214</td>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06:45:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TR</td>\n",
       "      <td>325.0</td>\n",
       "      <td>41.275333</td>\n",
       "      <td>28.75200</td>\n",
       "      <td>TN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.851002</td>\n",
       "      <td>10.22720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0480</td>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17:00:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>90.0</td>\n",
       "      <td>47.153198</td>\n",
       "      <td>-1.61073</td>\n",
       "      <td>TN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.875000</td>\n",
       "      <td>10.77550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0338</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15:50:00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMU</td>\n",
       "      <td>22.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>82.0</td>\n",
       "      <td>36.691002</td>\n",
       "      <td>3.21541</td>\n",
       "      <td>TN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.851002</td>\n",
       "      <td>10.22720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID      DATOP     FLTID DEPSTN ARRSTN                 STD   \n",
       "0  train_id_0 2016-01-03  TU 0712     CMN    TUN 2016-01-03 10:30:00  \\\n",
       "1  train_id_1 2016-01-13  TU 0757     MXP    TUN 2016-01-13 15:05:00   \n",
       "2  train_id_2 2016-01-16  TU 0214     TUN    IST 2016-01-16 04:10:00   \n",
       "3  train_id_3 2016-01-17  TU 0480     DJE    NTE 2016-01-17 14:10:00   \n",
       "4  train_id_4 2016-01-17  TU 0338     TUN    ALG 2016-01-17 14:30:00   \n",
       "\n",
       "                  STA STATUS         AC  target country_arrive   \n",
       "0 2016-01-03 12:55:00    ATA  TU 32AIMN   260.0             TN  \\\n",
       "1 2016-01-13 16:55:00    ATA  TU 31BIMO    20.0             TN   \n",
       "2 2016-01-16 06:45:00    ATA  TU 32AIMN     0.0             TR   \n",
       "3 2016-01-17 17:00:00    ATA  TU 736IOK     0.0             FR   \n",
       "4 2016-01-17 15:50:00    ATA  TU 320IMU    22.0             DZ   \n",
       "\n",
       "   elevation_arrive  lat_arrive  lon_arrive country_depart  elevation_depart   \n",
       "0              22.0   36.851002    10.22720             MA             656.0  \\\n",
       "1              22.0   36.851002    10.22720             IT             768.0   \n",
       "2             325.0   41.275333    28.75200             TN              22.0   \n",
       "3              90.0   47.153198    -1.61073             TN              19.0   \n",
       "4              82.0   36.691002     3.21541             TN              22.0   \n",
       "\n",
       "   lat_depart  lon_depart  \n",
       "0   33.367500    -7.58997  \n",
       "1   45.630600     8.72811  \n",
       "2   36.851002    10.22720  \n",
       "3   33.875000    10.77550  \n",
       "4   36.851002    10.22720  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX COLUMN NAMES Function - general function build out with time\n",
    "def fix_column_names(input_dataset):\n",
    "    infun_data = input_dataset\n",
    "    # pull the starting columns to show at the end the transformation \n",
    "    starting_columns = list(infun_data.columns)\n",
    "    # carry out the changes; remove spaces and hyphens, lower case everything\n",
    "    infun_data.columns = infun_data.columns.str.replace(' ','_')\n",
    "    infun_data.columns = infun_data.columns.str.lower()\n",
    "    infun_data.columns = infun_data.columns.str.replace('-', '_')\n",
    "    # pull the ending columns to show at the end the transformation \n",
    "    ending_columns = list(infun_data.columns)\n",
    "    # create a dictionary of the old names vs the new names \n",
    "    dict_of_names = {'old column name': starting_columns, 'new column name': ending_columns}\n",
    "    dataframe_of_column_names = df = pd.DataFrame(dict_of_names) \n",
    "    print(dataframe_of_column_names)\n",
    "    return infun_data\n",
    "\n",
    "df = fix_column_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you must make the dataset equal to the function\n",
    "# i.e. df = del_duplicates(df)\n",
    "def del_duplicates(input_dataset):\n",
    "    infun_data = input_dataset\n",
    "    # check for duplicates \n",
    "    print(infun_data.duplicated().value_counts())\n",
    "    # remove duplicates\n",
    "    infun_data = infun_data.drop_duplicates()\n",
    "    # reset index inplace\n",
    "    infun_data.reset_index(inplace=True, drop=True)\n",
    "    return infun_data\n",
    "    \n",
    "df = del_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which are statistical continous values?\n",
    "# which are statistical quantitative values?\n",
    "\n",
    "\n",
    "# check the different columns\n",
    "# is a column a unique identifier? \n",
    "# can it be dropped to a unique identifier table, \n",
    "# i.e. unique identifier and then name, address, ticket number etc. (info table)\n",
    "# postcode/zipcode an example of a none unique identifier, things that can't be grouped\n",
    "df.dtypes\n",
    "\n",
    "def table_nuniques(input_dataset):\n",
    "    nunique_dictionary = {'column name': [], 'nuniques': [], 'uniques':[], 'dtype' : []}\n",
    "    infun_data = input_dataset\n",
    "    columnlist = list(infun_data.columns)\n",
    "    for i in columnlist: \n",
    "        nunique_dictionary['column name'].append(i)\n",
    "        nunique_dictionary['nuniques'].append(infun_data[i].nunique())        \n",
    "        nunique_dictionary['uniques'].append(infun_data[i].unique())\n",
    "        nunique_dictionary['dtype'].append(infun_data[i].dtype)\n",
    "    # print the dictionary as a dataframe\n",
    "    return pd.DataFrame(nunique_dictionary)\n",
    "\n",
    "table_nuniques(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  no na was found!!\n",
    "print(df.isnull().sum())\n",
    "#  lots of 0 was found!!\n",
    "print((df == 0).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
