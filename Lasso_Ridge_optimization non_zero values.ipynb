{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = (11, 7)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna \n",
    "\n",
    "# Feel free to add all the libraries you need\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/ordinalencoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['target']!=0]\n",
    "df = df1.drop(['dep_lat','dep_lon','arr_lat','arr_lon', 'day', 'year', 'arr_elevation', 'dep_elevation'], axis=1)\n",
    "#df['status']=df['status']*df['status']*df['status']\n",
    "#df['arr_iata']=df['arr_iata']*df['arr_iata']*df['arr_iata']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define features and target\n",
    "features = df.columns.tolist()\n",
    "features.remove('target')\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# LETS DO FEATURE ENGINEERING.....gonna square some shit \n",
    "# generate interaction features to the 3rd degree\n",
    "p = PolynomialFeatures(interaction_only=False, include_bias=False, degree=1)\n",
    "X_poly = p.fit_transform(X)\n",
    "p.n_output_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unscaled, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=12, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler \n",
    "scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature engineering -- create function to pull out coefficients/features\n",
    "## add a gradient descent\n",
    "def lasso_optimization(x123_train):\n",
    "    eval_metrics_dictionary = {'mean_r2':[],'mean_MAPE':[],'mean_MSE':[],'std_r2':[],'std_MAPE':[],'std_MSE':[],'score':[], 'alpha':[], 'coeff_used':[], 'coefficients':[], 'intercept':[]}\n",
    "\n",
    "    # initialize and train model with (default value) alpha = 0.5\n",
    "    # for i in [0.1, 1, 10,100,1000, 10000, 33000,66000, 100000, 330000,660000,1000000, 3300000,6600000,10000000,33000000,66000000,100000000]:\n",
    "    for i in [0.12,0.15]:\n",
    "\n",
    "        model = Lasso(alpha=i, max_iter=int(2000))\n",
    "        model.fit(x123_train,y_train)\n",
    "        \n",
    "        ## EVALUATION METRICS\n",
    "        # you should really use cross_val_score rather than testing against the test set\n",
    "        ## use cross validation for \n",
    "        score = cross_validate(model, x123_train, y_train, scoring=('neg_mean_absolute_percentage_error', 'r2', 'neg_mean_squared_error'), cv=3)\n",
    "        \n",
    "        ## pull out the scores\n",
    "        mean_MAPE = -1*np.mean(score['test_neg_mean_absolute_percentage_error'])\n",
    "        mean_r2 = np.mean(score['test_r2'])\n",
    "        mean_MSE = -1*np.mean(score['test_neg_mean_squared_error'])\n",
    "        std_MAPE = np.std(score['test_neg_mean_absolute_percentage_error'])\n",
    "        std_r2 = np.std(score['test_r2'])\n",
    "        std_MSE = np.std(score['test_neg_mean_squared_error'])\n",
    "        coeff_used = np.sum(model.coef_!=0)\n",
    "        coefficients = model.coef_\n",
    "        intercept = model.intercept_\n",
    "\n",
    "        dicKeys = ['mean_MAPE','mean_r2','mean_MSE','std_MAPE','std_r2','std_MSE','score','alpha','coeff_used', 'coefficients', 'intercept'] \n",
    "        dicValues = [mean_MAPE, mean_r2, mean_MSE, std_MAPE, std_r2, std_MSE, len(score), i, coeff_used, coefficients, intercept]\n",
    "        for (keyi, vali) in zip(dicKeys, dicValues):\n",
    "            eval_metrics_dictionary[keyi].append(vali)\n",
    "        #eval_metrics_dictionary['mean_MAPE'].append(mean_MAPE)\n",
    "        #eval_metrics_dictionary['mean_r2'].append(mean_r2)\n",
    "        #eval_metrics_dictionary['mean_MSE'].append(mean_MSE)\n",
    "        #eval_metrics_dictionary['std_MAPE'].append(std_MAPE)\n",
    "        #eval_metrics_dictionary['std_r2'].append(std_r2)\n",
    "        #eval_metrics_dictionary['std_MSE'].append(std_MSE)\n",
    "        #eval_metrics_dictionary['score'].append(len(score))\n",
    "        #eval_metrics_dictionary['alpha'].append(i)\n",
    "        #eval_metrics_dictionary['coeff_used'].append(coeff_used)\n",
    "\n",
    "    df_framework = pd.DataFrame(eval_metrics_dictionary)\n",
    "    # * by the r2_score that is closest to 1 --- you want to minimise the values of the rest, dont need to include RMSE, you overweight that value\n",
    "    df_framework['combined_score'] = abs(abs(1 - df_framework['mean_r2'])*df_framework['mean_MSE']*df_framework['mean_MAPE'])\n",
    "    df_bestvalue = df_framework[df_framework['combined_score']==min(df_framework['combined_score'])]\n",
    "    return df_bestvalue\n",
    "#return df_framework.sort_values('combined_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_r2</th>\n",
       "      <th>mean_MAPE</th>\n",
       "      <th>mean_MSE</th>\n",
       "      <th>std_r2</th>\n",
       "      <th>std_MAPE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>coeff_used</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>intercept</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018695</td>\n",
       "      <td>3.001788</td>\n",
       "      <td>21211.999672</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.076588</td>\n",
       "      <td>1729.398338</td>\n",
       "      <td>5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14</td>\n",
       "      <td>[31.71810494464688, 19.158839435453984, -11.74...</td>\n",
       "      <td>5.966296</td>\n",
       "      <td>62483.559933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_r2  mean_MAPE      mean_MSE    std_r2  std_MAPE      std_MSE  score   \n",
       "0  0.018695   3.001788  21211.999672  0.003973  0.076588  1729.398338      5  \\\n",
       "\n",
       "   alpha  coeff_used                                       coefficients   \n",
       "0   0.12          14  [31.71810494464688, 19.158839435453984, -11.74...  \\\n",
       "\n",
       "   intercept  combined_score  \n",
       "0   5.966296    62483.559933  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi = lasso_optimization(X_train)\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take list of coefficients - if more than zero \n",
    "# keep the name of the poly feature\n",
    "# keep the non-zero poly features values\n",
    "featurenames = list(p.get_feature_names_out(X.columns))\n",
    "## pull the list of coefficients -- some funnny stuff needs to be done because of array stuff, basically reset_index\n",
    "coefficient_list = list(hi['coefficients'].reset_index()['coefficients'][0]) \n",
    "\n",
    "### creature a dictionary of features and coefficients and then turn into dataframe\n",
    "feature_coefficient_dict = {'feature':[], 'coefficient':[]}\n",
    "for (feaI, coeI) in zip(featurenames, coefficient_list): \n",
    "    if coeI != 0: \n",
    "        feature_coefficient_dict['feature'].append(feaI)\n",
    "        feature_coefficient_dict['coefficient'].append(coeI)\n",
    "        \n",
    "pd.DataFrame(feature_coefficient_dict)\n",
    "feature_selection = feature_coefficient_dict['feature']\n",
    "#### with the coefficients create a new np.array to \n",
    "ridge_Xtrain = np.array(pd.DataFrame(X_train, columns= p.get_feature_names_out(X.columns))[feature_selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_time</td>\n",
       "      <td>50.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datop</td>\n",
       "      <td>31.718105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arr_country</td>\n",
       "      <td>29.675554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dep_country</td>\n",
       "      <td>22.960676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>flight_time_in_min</td>\n",
       "      <td>22.733632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fltid</td>\n",
       "      <td>19.158839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>month</td>\n",
       "      <td>12.544491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>season</td>\n",
       "      <td>3.501632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dep_iata</td>\n",
       "      <td>-0.412945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac</td>\n",
       "      <td>-5.196107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>international_flight</td>\n",
       "      <td>-5.263957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>average_flight_speed_km_h</td>\n",
       "      <td>-6.359715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elevation_dif</td>\n",
       "      <td>-9.747652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depstn</td>\n",
       "      <td>-11.749676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  coefficient\n",
       "13                   std_time    50.006660\n",
       "0                       datop    31.718105\n",
       "7                 arr_country    29.675554\n",
       "6                 dep_country    22.960676\n",
       "10         flight_time_in_min    22.733632\n",
       "1                       fltid    19.158839\n",
       "4                       month    12.544491\n",
       "8                      season     3.501632\n",
       "5                    dep_iata    -0.412945\n",
       "3                          ac    -5.196107\n",
       "12       international_flight    -5.263957\n",
       "11  average_flight_speed_km_h    -6.359715\n",
       "9               elevation_dif    -9.747652\n",
       "2                      depstn   -11.749676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hi = lasso_optimization(Xtrain1)\n",
    "pd.DataFrame(feature_coefficient_dict).sort_values('coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_optimization(number_of_trials):\n",
    "    # input to study should be dataset and number of iterations\n",
    "    eval_metrics_dictionary = {'mean_r2':[],'mean_MAPE':[],'mean_MSE':[],'std_r2':[],'std_MAPE':[],'std_MSE':[],'score':[]}\n",
    "    ridge_opt_dictionary = { 'alpha': [], 'intercept' : [], 'tol': [], 'solver':[], 'no_of_coefficients':[]}\n",
    "\n",
    "    def objective(trial):\n",
    "        ## HYPER PARAMETER TUNING\n",
    "        alpha = trial.suggest_float(\"alpha\", 0, 100)\n",
    "        intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
    "        tol = trial.suggest_float(\"tol\", 0.001, 1, log=True)\n",
    "        solver = trial.suggest_categorical(\"solver\", [\"auto\", \"svd\",\"cholesky\", \"lsqr\", \"saga\", \"sag\"])\n",
    "\n",
    "        ## MODEL SELECTION\n",
    "        ## Create Model\n",
    "        model = Ridge(alpha=alpha,fit_intercept=intercept,tol=tol,solver=solver)\n",
    "        ## Fit Model\n",
    "        model.fit(ridge_Xtrain, y_train)\n",
    "        \n",
    "        # Function parameters for cross_val_score; \n",
    "        #   - estimator - The model object to use to fit the data\n",
    "        #   - X - The data to fit the model on\n",
    "        #   - y - The target of the model\n",
    "        #   - scoring - The error metric to use\n",
    "        #   - cv - The number of splits to use\n",
    "        \n",
    "        # error score to use; \n",
    "        #   - accuracy\n",
    "        #   - balanced_accuracy\n",
    "        #   - roc_auc\n",
    "        #   - f1\n",
    "        #   - neg_mean_absolute_error\n",
    "        #   - neg_root_mean_squared_error\n",
    "        #   - r2\n",
    "        \n",
    "        ## EVALUATION METRICS\n",
    "        # you should really use cross_val_score rather than testing against the test set\n",
    "        score = cross_validate(model, ridge_Xtrain, y_train, scoring=('neg_mean_absolute_percentage_error', 'r2', 'neg_mean_squared_error'), cv=3)\n",
    "        mean_MAPE = -1*np.mean(score['test_neg_mean_absolute_percentage_error'])\n",
    "        mean_r2 = np.mean(score['test_r2'])\n",
    "        mean_MSE = -1*np.mean(score['test_neg_mean_squared_error'])\n",
    "        std_MAPE = np.std(score['test_neg_mean_absolute_percentage_error'])\n",
    "        std_r2 = np.std(score['test_r2'])\n",
    "        std_MSE = np.std(score['test_neg_mean_squared_error'])\n",
    "        \n",
    "        \"\"\"\n",
    "        y_pred_train= ridge_regressor.predict(X_test)\n",
    "            \n",
    "        Evaluation metrics;\n",
    "        - R squared\n",
    "        - MSE\n",
    "        - RMSE\n",
    "        - MAPE\n",
    "        \n",
    "        infun_MSE = mean_squared_error(y_test,y_pred_train)\n",
    "        infun_RMSE = math.sqrt(infun_MSE)\n",
    "        infun_r2 = r2_score(y_test, y_pred_train) \n",
    "        infun_MAPE = mean_absolute_percentage_error(y_test, y_pred_train) \n",
    "        max_coeff = ridge_regressor.coef_.round(3)\n",
    "        eval_metrics_dictionary['r2'].append(infun_r2)\n",
    "        eval_metrics_dictionary['MSE'].append(infun_MSE)\n",
    "        eval_metrics_dictionary['RMSE'].append(infun_RMSE)\n",
    "        eval_metrics_dictionary['MAPE'].append(infun_MAPE)\n",
    "        \"\"\"\n",
    "        coeff_used = np.sum(model.coef_!=0)\n",
    "\n",
    "        eval_metrics_dictionary['mean_MAPE'].append(mean_MAPE)\n",
    "        eval_metrics_dictionary['mean_r2'].append(mean_r2)\n",
    "        eval_metrics_dictionary['mean_MSE'].append(mean_MSE)\n",
    "        eval_metrics_dictionary['std_MAPE'].append(std_MAPE)\n",
    "        eval_metrics_dictionary['std_r2'].append(std_r2)\n",
    "        eval_metrics_dictionary['std_MSE'].append(std_MSE)\n",
    "        eval_metrics_dictionary['score'].append(len(score))\n",
    "        \n",
    "        ridge_opt_dictionary['alpha'].append(alpha)\n",
    "        ridge_opt_dictionary['intercept'].append(intercept)\n",
    "        ridge_opt_dictionary['tol'].append(tol)\n",
    "        ridge_opt_dictionary['solver'].append(solver)\n",
    "        ridge_opt_dictionary['no_of_coefficients'].append(coeff_used)\n",
    "\n",
    "        return mean_MSE*mean_MAPE*(1-mean_r2)*(1-mean_r2)\n",
    "        #return mean_MSE\n",
    "\n",
    "    study2 = optuna.create_study(study_name=\"RidgeRegression Optimization\")\n",
    "    study2.optimize(objective, n_trials=number_of_trials)\n",
    "    df_framework = pd.DataFrame(eval_metrics_dictionary)\n",
    "    # * by the r2_score that is closest to 1 --- you want to minimise the values of the rest, dont need to include RMSE, you overweight that value\n",
    "    df_framework['combined_score'] = abs(abs(1 - df_framework['mean_r2'])*df_framework['mean_MSE']*df_framework['mean_MAPE'])\n",
    "    df_bestvalue = df_framework[df_framework['combined_score']==min(df_framework['combined_score'])]\n",
    "    return df_bestvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-01 13:30:04,558] A new study created in memory with name: RidgeRegression Optimization\n",
      "[I 2023-09-01 13:30:04,589] Trial 0 finished with value: 73754.53185984762 and parameters: {'alpha': 31.691610658028857, 'fit_intercept': False, 'tol': 0.4532446649018952, 'solver': 'sag'}. Best is trial 0 with value: 73754.53185984762.\n",
      "[I 2023-09-01 13:30:04,601] Trial 1 finished with value: 61368.876293216825 and parameters: {'alpha': 61.64269098255453, 'fit_intercept': True, 'tol': 0.01684876219009207, 'solver': 'cholesky'}. Best is trial 1 with value: 61368.876293216825.\n",
      "[I 2023-09-01 13:30:04,615] Trial 2 finished with value: 60797.288798588816 and parameters: {'alpha': 6.324144071433002, 'fit_intercept': False, 'tol': 0.011421463748602896, 'solver': 'auto'}. Best is trial 2 with value: 60797.288798588816.\n",
      "[I 2023-09-01 13:30:04,643] Trial 3 finished with value: 61520.59531617049 and parameters: {'alpha': 87.55893436252715, 'fit_intercept': True, 'tol': 0.0010841955747050106, 'solver': 'svd'}. Best is trial 2 with value: 60797.288798588816.\n",
      "[I 2023-09-01 13:30:04,727] Trial 4 finished with value: 60951.39842547042 and parameters: {'alpha': 27.376743650673163, 'fit_intercept': False, 'tol': 0.0021354102063703925, 'solver': 'sag'}. Best is trial 2 with value: 60797.288798588816.\n",
      "[I 2023-09-01 13:30:04,739] Trial 5 finished with value: 61230.68257707695 and parameters: {'alpha': 39.12557427899181, 'fit_intercept': True, 'tol': 0.0036630717949263474, 'solver': 'cholesky'}. Best is trial 2 with value: 60797.288798588816.\n",
      "[I 2023-09-01 13:30:04,763] Trial 6 finished with value: 61005.79369977914 and parameters: {'alpha': 0.6050914213895031, 'fit_intercept': True, 'tol': 0.025573051458181843, 'solver': 'svd'}. Best is trial 2 with value: 60797.288798588816.\n",
      "[I 2023-09-01 13:30:04,787] Trial 7 finished with value: 60764.315799822216 and parameters: {'alpha': 1.746474351054761, 'fit_intercept': False, 'tol': 0.027988526319922304, 'solver': 'svd'}. Best is trial 7 with value: 60764.315799822216.\n",
      "[I 2023-09-01 13:30:04,814] Trial 8 finished with value: 61156.06442289744 and parameters: {'alpha': 27.374589125995474, 'fit_intercept': True, 'tol': 0.36227277479732534, 'solver': 'svd'}. Best is trial 7 with value: 60764.315799822216.\n",
      "[I 2023-09-01 13:30:04,836] Trial 9 finished with value: 61194.57525515568 and parameters: {'alpha': 33.41396478653241, 'fit_intercept': True, 'tol': 0.15380216048172812, 'solver': 'auto'}. Best is trial 7 with value: 60764.315799822216.\n",
      "[I 2023-09-01 13:30:04,909] Trial 10 finished with value: 61510.98937501333 and parameters: {'alpha': 60.19421197009254, 'fit_intercept': False, 'tol': 0.06997947763671651, 'solver': 'saga'}. Best is trial 7 with value: 60764.315799822216.\n",
      "[I 2023-09-01 13:30:04,927] Trial 11 finished with value: 60756.12039632169 and parameters: {'alpha': 0.5517569147430801, 'fit_intercept': False, 'tol': 0.010156261161072018, 'solver': 'auto'}. Best is trial 11 with value: 60756.12039632169.\n",
      "[I 2023-09-01 13:30:04,947] Trial 12 finished with value: 61707.75779183367 and parameters: {'alpha': 11.500733347121352, 'fit_intercept': False, 'tol': 0.007800894149847156, 'solver': 'lsqr'}. Best is trial 11 with value: 60756.12039632169.\n",
      "[I 2023-09-01 13:30:04,964] Trial 13 finished with value: 60849.21736387719 and parameters: {'alpha': 13.445641622365718, 'fit_intercept': False, 'tol': 0.025314979067094078, 'solver': 'auto'}. Best is trial 11 with value: 60756.12039632169.\n",
      "[I 2023-09-01 13:30:05,017] Trial 14 finished with value: 60119.9654374659 and parameters: {'alpha': 1.528851245475037, 'fit_intercept': False, 'tol': 0.05612772183171303, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,066] Trial 15 finished with value: 61385.47307135012 and parameters: {'alpha': 16.08626814759348, 'fit_intercept': False, 'tol': 0.06710394171899925, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,153] Trial 16 finished with value: 60886.35692298763 and parameters: {'alpha': 18.05699986148185, 'fit_intercept': False, 'tol': 0.005086320949552407, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,172] Trial 17 finished with value: 63731.52669764763 and parameters: {'alpha': 2.8006054004517114, 'fit_intercept': False, 'tol': 0.010665209368217283, 'solver': 'lsqr'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,191] Trial 18 finished with value: 60893.48167807551 and parameters: {'alpha': 19.838891135169757, 'fit_intercept': False, 'tol': 0.060005482523598615, 'solver': 'auto'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,218] Trial 19 finished with value: 81968.21946921226 and parameters: {'alpha': 43.6626477216362, 'fit_intercept': False, 'tol': 0.7633110352872562, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,236] Trial 20 finished with value: 60907.23573779931 and parameters: {'alpha': 21.908075073398315, 'fit_intercept': False, 'tol': 0.1213286642788065, 'solver': 'auto'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,270] Trial 21 finished with value: 60786.64201245107 and parameters: {'alpha': 4.865994881454078, 'fit_intercept': False, 'tol': 0.03262922622934487, 'solver': 'svd'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,303] Trial 22 finished with value: 60819.53183579306 and parameters: {'alpha': 9.345829143820595, 'fit_intercept': False, 'tol': 0.0169204086754393, 'solver': 'svd'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,362] Trial 23 finished with value: 60436.92946603229 and parameters: {'alpha': 5.40782597567808, 'fit_intercept': False, 'tol': 0.03521972290028674, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,419] Trial 24 finished with value: 60294.75267436109 and parameters: {'alpha': 0.7897804392816807, 'fit_intercept': False, 'tol': 0.05034534520524751, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,476] Trial 25 finished with value: 60578.889380795634 and parameters: {'alpha': 13.16392783563359, 'fit_intercept': False, 'tol': 0.05188642788941405, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,521] Trial 26 finished with value: 61080.51642955017 and parameters: {'alpha': 10.41908314305012, 'fit_intercept': False, 'tol': 0.1376692109159123, 'solver': 'saga'}. Best is trial 14 with value: 60119.9654374659.\n",
      "[I 2023-09-01 13:30:05,578] Trial 27 finished with value: 60044.8755913277 and parameters: {'alpha': 22.403609698641528, 'fit_intercept': False, 'tol': 0.04466152496792088, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,627] Trial 28 finished with value: 60285.18546995678 and parameters: {'alpha': 21.871063708195404, 'fit_intercept': False, 'tol': 0.0999022161882633, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,672] Trial 29 finished with value: 61514.180024251415 and parameters: {'alpha': 25.598829507132294, 'fit_intercept': False, 'tol': 0.24258276366054032, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,718] Trial 30 finished with value: 60083.70262438506 and parameters: {'alpha': 32.8205026860596, 'fit_intercept': False, 'tol': 0.09145843717792877, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,764] Trial 31 finished with value: 60691.636095936105 and parameters: {'alpha': 33.036353324841485, 'fit_intercept': False, 'tol': 0.08252315737136492, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,815] Trial 32 finished with value: 60714.72163806678 and parameters: {'alpha': 22.398810367271693, 'fit_intercept': False, 'tol': 0.08980028174973638, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,834] Trial 33 finished with value: 60996.44442161226 and parameters: {'alpha': 36.48715735073836, 'fit_intercept': False, 'tol': 0.24082097912109607, 'solver': 'cholesky'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,883] Trial 34 finished with value: 61109.137082120316 and parameters: {'alpha': 29.43076714223815, 'fit_intercept': True, 'tol': 0.1004911603437375, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,939] Trial 35 finished with value: 60321.671653606274 and parameters: {'alpha': 18.17876215427227, 'fit_intercept': False, 'tol': 0.043997010165117006, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:05,981] Trial 36 finished with value: 61107.30649037511 and parameters: {'alpha': 39.759401038719936, 'fit_intercept': False, 'tol': 0.1711695549067011, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,000] Trial 37 finished with value: 61131.52366283911 and parameters: {'alpha': 23.54620452457046, 'fit_intercept': True, 'tol': 0.09428358745363187, 'solver': 'cholesky'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,066] Trial 38 finished with value: 61100.426807089345 and parameters: {'alpha': 46.7892941560964, 'fit_intercept': False, 'tol': 0.017879036166920933, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,089] Trial 39 finished with value: 62078.54332390305 and parameters: {'alpha': 30.202884241253656, 'fit_intercept': True, 'tol': 0.05236764569518523, 'solver': 'lsqr'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,145] Trial 40 finished with value: 61043.321107073716 and parameters: {'alpha': 8.549419442020756, 'fit_intercept': False, 'tol': 0.03444497282756922, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,204] Trial 41 finished with value: 60535.467312338005 and parameters: {'alpha': 6.405985944985891, 'fit_intercept': False, 'tol': 0.045383298917301626, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,257] Trial 42 finished with value: 61216.19260810569 and parameters: {'alpha': 13.757571900791746, 'fit_intercept': False, 'tol': 0.07123887271979731, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,312] Trial 43 finished with value: 61238.33035544316 and parameters: {'alpha': 26.773443043526548, 'fit_intercept': False, 'tol': 0.047710838127673384, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,358] Trial 44 finished with value: 64650.61622256115 and parameters: {'alpha': 16.902080802879066, 'fit_intercept': False, 'tol': 0.12933316083850505, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,471] Trial 45 finished with value: 60125.83401401018 and parameters: {'alpha': 0.4943850040566381, 'fit_intercept': False, 'tol': 0.021522184545810483, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,538] Trial 46 finished with value: 61048.37222957042 and parameters: {'alpha': 7.792899147951981, 'fit_intercept': True, 'tol': 0.021529195097585545, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,600] Trial 47 finished with value: 60887.4184450347 and parameters: {'alpha': 20.930330846139565, 'fit_intercept': False, 'tol': 0.023581281867852986, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,667] Trial 48 finished with value: 60435.57980332211 and parameters: {'alpha': 13.772639640689558, 'fit_intercept': False, 'tol': 0.034951242460273715, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,684] Trial 49 finished with value: 60752.97406941226 and parameters: {'alpha': 0.07941578699867269, 'fit_intercept': False, 'tol': 0.012850896522582457, 'solver': 'cholesky'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,735] Trial 50 finished with value: 61270.74288233499 and parameters: {'alpha': 34.186980499058, 'fit_intercept': True, 'tol': 0.07406560581754273, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,827] Trial 51 finished with value: 60809.56998979262 and parameters: {'alpha': 3.933910794293314, 'fit_intercept': False, 'tol': 0.02777091755326755, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,847] Trial 52 finished with value: 67317.58109062177 and parameters: {'alpha': 2.0180868940188783, 'fit_intercept': False, 'tol': 0.06154552690958047, 'solver': 'lsqr'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,896] Trial 53 finished with value: 60119.098419695154 and parameters: {'alpha': 9.777702167373956, 'fit_intercept': False, 'tol': 0.10380075932815606, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,945] Trial 54 finished with value: 61135.44728209369 and parameters: {'alpha': 10.000368950750172, 'fit_intercept': False, 'tol': 0.10682885821201968, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:06,991] Trial 55 finished with value: 61566.437061167606 and parameters: {'alpha': 15.870786448725315, 'fit_intercept': False, 'tol': 0.16652297862428447, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,042] Trial 56 finished with value: 60954.20359320112 and parameters: {'alpha': 24.171830882003086, 'fit_intercept': False, 'tol': 0.077616131980497, 'solver': 'saga'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,072] Trial 57 finished with value: 60792.78840593535 and parameters: {'alpha': 5.7091852073879625, 'fit_intercept': False, 'tol': 0.09999958746312991, 'solver': 'svd'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,091] Trial 58 finished with value: 60890.03795125753 and parameters: {'alpha': 19.327593753573982, 'fit_intercept': False, 'tol': 0.03975413910452188, 'solver': 'auto'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,155] Trial 59 finished with value: 60257.172809408505 and parameters: {'alpha': 12.930910857340502, 'fit_intercept': False, 'tol': 0.05988042935627105, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,217] Trial 60 finished with value: 61359.73237564901 and parameters: {'alpha': 11.483113072039417, 'fit_intercept': False, 'tol': 0.06015888829894176, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,294] Trial 61 finished with value: 60909.86312190168 and parameters: {'alpha': 8.318370366838016, 'fit_intercept': False, 'tol': 0.028017701789769762, 'solver': 'sag'}. Best is trial 27 with value: 60044.8755913277.\n",
      "[I 2023-09-01 13:30:07,359] Trial 62 finished with value: 59366.60546453527 and parameters: {'alpha': 13.598145662602493, 'fit_intercept': False, 'tol': 0.06273312304381033, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,439] Trial 63 finished with value: 61243.30179983479 and parameters: {'alpha': 4.319546865433718, 'fit_intercept': False, 'tol': 0.038098557766153736, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,494] Trial 64 finished with value: 59497.48239148346 and parameters: {'alpha': 15.316331253502888, 'fit_intercept': False, 'tol': 0.06347680307924858, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,547] Trial 65 finished with value: 60329.462497774664 and parameters: {'alpha': 15.637094634564228, 'fit_intercept': False, 'tol': 0.07977062201111959, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,621] Trial 66 finished with value: 60931.592643181415 and parameters: {'alpha': 10.594831229098965, 'fit_intercept': False, 'tol': 0.04179838289139275, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,705] Trial 67 finished with value: 60495.122471658855 and parameters: {'alpha': 6.452142142443644, 'fit_intercept': False, 'tol': 0.02049201080811633, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,725] Trial 68 finished with value: 67288.66975231335 and parameters: {'alpha': 19.47409502943227, 'fit_intercept': False, 'tol': 0.028636739634963895, 'solver': 'lsqr'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,756] Trial 69 finished with value: 60773.006767512896 and parameters: {'alpha': 2.9771261730787293, 'fit_intercept': False, 'tol': 0.12400467295285364, 'solver': 'svd'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,777] Trial 70 finished with value: 61151.32883091008 and parameters: {'alpha': 26.635308801485362, 'fit_intercept': True, 'tol': 0.055702909234346475, 'solver': 'cholesky'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,838] Trial 71 finished with value: 61353.73407979558 and parameters: {'alpha': 14.623979178657747, 'fit_intercept': False, 'tol': 0.058518538648839366, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,901] Trial 72 finished with value: 62811.70175013607 and parameters: {'alpha': 11.548376913440803, 'fit_intercept': False, 'tol': 0.06945887132035759, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:07,957] Trial 73 finished with value: 60477.79006394665 and parameters: {'alpha': 17.73264075998504, 'fit_intercept': False, 'tol': 0.04856657124427095, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,010] Trial 74 finished with value: 62565.62840831623 and parameters: {'alpha': 12.720448113087976, 'fit_intercept': False, 'tol': 0.09038264984685446, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,028] Trial 75 finished with value: 60755.13706489887 and parameters: {'alpha': 0.4049856069853537, 'fit_intercept': False, 'tol': 0.03135044066921753, 'solver': 'auto'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,096] Trial 76 finished with value: 60823.22790614566 and parameters: {'alpha': 7.359688373847208, 'fit_intercept': False, 'tol': 0.065567382514261, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,153] Trial 77 finished with value: 61366.423389735144 and parameters: {'alpha': 23.057532637496074, 'fit_intercept': False, 'tol': 0.03890336114837726, 'solver': 'saga'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,212] Trial 78 finished with value: 60968.31478477655 and parameters: {'alpha': 29.190263723850933, 'fit_intercept': False, 'tol': 0.051181323263887024, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,257] Trial 79 finished with value: 61424.125814739746 and parameters: {'alpha': 3.3914551408245392, 'fit_intercept': False, 'tol': 0.11410260703135343, 'solver': 'saga'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,315] Trial 80 finished with value: 62625.500468847196 and parameters: {'alpha': 9.818539401436336, 'fit_intercept': False, 'tol': 0.08249910779298722, 'solver': 'sag'}. Best is trial 62 with value: 59366.60546453527.\n",
      "[I 2023-09-01 13:30:08,363] Trial 81 finished with value: 57741.95630694172 and parameters: {'alpha': 21.285805425274816, 'fit_intercept': False, 'tol': 0.13617810914347353, 'solver': 'saga'}. Best is trial 81 with value: 57741.95630694172.\n",
      "[I 2023-09-01 13:30:08,406] Trial 82 finished with value: 61332.37308100352 and parameters: {'alpha': 17.115867163497242, 'fit_intercept': False, 'tol': 0.1362510840627794, 'solver': 'saga'}. Best is trial 81 with value: 57741.95630694172.\n",
      "[I 2023-09-01 13:30:08,455] Trial 83 finished with value: 60879.991360136104 and parameters: {'alpha': 20.612736235775344, 'fit_intercept': False, 'tol': 0.06541433245478093, 'solver': 'saga'}. Best is trial 81 with value: 57741.95630694172.\n",
      "[I 2023-09-01 13:30:08,495] Trial 84 finished with value: 56764.61633316871 and parameters: {'alpha': 14.04060077015772, 'fit_intercept': False, 'tol': 0.19721738812763848, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,541] Trial 85 finished with value: 61298.38383066981 and parameters: {'alpha': 24.329268468625823, 'fit_intercept': False, 'tol': 0.18096758553726233, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,588] Trial 86 finished with value: 61129.77294929508 and parameters: {'alpha': 15.597348433260702, 'fit_intercept': True, 'tol': 0.19812502928492964, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,633] Trial 87 finished with value: 61167.723112135776 and parameters: {'alpha': 8.156297114419623, 'fit_intercept': False, 'tol': 0.13639834901372327, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,678] Trial 88 finished with value: 60277.760173978946 and parameters: {'alpha': 21.239346545222396, 'fit_intercept': False, 'tol': 0.09997243281650688, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,718] Trial 89 finished with value: 63440.85991491991 and parameters: {'alpha': 28.585942990578072, 'fit_intercept': False, 'tol': 0.21933272314582145, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,764] Trial 90 finished with value: 59797.30098473138 and parameters: {'alpha': 4.659435007891647, 'fit_intercept': False, 'tol': 0.15135831615052955, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,804] Trial 91 finished with value: 59944.791668573824 and parameters: {'alpha': 5.77686528627728, 'fit_intercept': False, 'tol': 0.2983892996510131, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,840] Trial 92 finished with value: 71190.49832890608 and parameters: {'alpha': 5.7620422695870745, 'fit_intercept': False, 'tol': 0.2700418651463114, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,883] Trial 93 finished with value: 59792.217627592734 and parameters: {'alpha': 13.02654804572969, 'fit_intercept': False, 'tol': 0.1507828066472449, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,919] Trial 94 finished with value: 64720.02428143876 and parameters: {'alpha': 12.667540184025052, 'fit_intercept': False, 'tol': 0.32092469125822604, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:08,965] Trial 95 finished with value: 61052.10945064309 and parameters: {'alpha': 15.295342742990933, 'fit_intercept': False, 'tol': 0.15053014140854942, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,007] Trial 96 finished with value: 62446.762469921865 and parameters: {'alpha': 17.646842702051014, 'fit_intercept': False, 'tol': 0.16290436927744936, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,052] Trial 97 finished with value: 59514.31129713195 and parameters: {'alpha': 10.086187330010842, 'fit_intercept': False, 'tol': 0.11220811849251465, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,094] Trial 98 finished with value: 59304.3943596411 and parameters: {'alpha': 18.90875110113677, 'fit_intercept': False, 'tol': 0.19973226606465527, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,135] Trial 99 finished with value: 60387.74444685599 and parameters: {'alpha': 19.345333278111067, 'fit_intercept': False, 'tol': 0.19902747705917617, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,182] Trial 100 finished with value: 61121.78867160305 and parameters: {'alpha': 13.9018309202545, 'fit_intercept': True, 'tol': 0.11753701333133901, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,227] Trial 101 finished with value: 60643.47564722135 and parameters: {'alpha': 22.15815156903122, 'fit_intercept': False, 'tol': 0.1424306079012515, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,268] Trial 102 finished with value: 60770.22635241771 and parameters: {'alpha': 25.3284549887415, 'fit_intercept': False, 'tol': 0.15741909984565025, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,312] Trial 103 finished with value: 61623.29727229946 and parameters: {'alpha': 12.207071020941113, 'fit_intercept': False, 'tol': 0.18514408144901756, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,332] Trial 104 finished with value: 67290.80322508999 and parameters: {'alpha': 18.185198554686675, 'fit_intercept': False, 'tol': 0.2779522649071775, 'solver': 'lsqr'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,383] Trial 105 finished with value: 58662.32278198591 and parameters: {'alpha': 9.064114882650607, 'fit_intercept': False, 'tol': 0.08683651910101656, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,413] Trial 106 finished with value: 60820.3565863083 and parameters: {'alpha': 9.45840647019978, 'fit_intercept': False, 'tol': 0.115550159326784, 'solver': 'svd'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,434] Trial 107 finished with value: 60784.971086178644 and parameters: {'alpha': 4.63625219413224, 'fit_intercept': False, 'tol': 0.44678830694933014, 'solver': 'cholesky'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,477] Trial 108 finished with value: 64779.34874307678 and parameters: {'alpha': 8.109401844199775, 'fit_intercept': False, 'tol': 0.21926652380054332, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,498] Trial 109 finished with value: 60857.354016050114 and parameters: {'alpha': 14.591254619169499, 'fit_intercept': False, 'tol': 0.1618961273713155, 'solver': 'auto'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,546] Trial 110 finished with value: 60475.959860336305 and parameters: {'alpha': 11.114056447738534, 'fit_intercept': False, 'tol': 0.08644067517827145, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,596] Trial 111 finished with value: 60389.60711365313 and parameters: {'alpha': 16.099188475415065, 'fit_intercept': False, 'tol': 0.09333117904041863, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,642] Trial 112 finished with value: 60495.19422046018 and parameters: {'alpha': 7.469776554201971, 'fit_intercept': False, 'tol': 0.12485728476417587, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,693] Trial 113 finished with value: 61160.14290581038 and parameters: {'alpha': 19.944273399427715, 'fit_intercept': False, 'tol': 0.11012707572430444, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,742] Trial 114 finished with value: 60399.752321414795 and parameters: {'alpha': 31.21950455497388, 'fit_intercept': False, 'tol': 0.0784993908586119, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,781] Trial 115 finished with value: 61659.54206678266 and parameters: {'alpha': 11.612688825689494, 'fit_intercept': False, 'tol': 0.18435699496753927, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,829] Trial 116 finished with value: 60143.36309687263 and parameters: {'alpha': 2.5784400438865553, 'fit_intercept': False, 'tol': 0.15088176464470607, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,875] Trial 117 finished with value: 59669.64049876779 and parameters: {'alpha': 23.093442080425238, 'fit_intercept': False, 'tol': 0.12830894369463178, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,914] Trial 118 finished with value: 61654.11568717786 and parameters: {'alpha': 5.898235408551224, 'fit_intercept': False, 'tol': 0.2198542478479099, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,965] Trial 119 finished with value: 61309.960010709794 and parameters: {'alpha': 23.61005398900696, 'fit_intercept': False, 'tol': 0.1295159258644024, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:09,988] Trial 120 finished with value: 63835.27633640104 and parameters: {'alpha': 14.138216511803444, 'fit_intercept': True, 'tol': 0.27081432140058165, 'solver': 'lsqr'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,044] Trial 121 finished with value: 60891.84503639363 and parameters: {'alpha': 27.084144078810855, 'fit_intercept': False, 'tol': 0.07108422973975015, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,090] Trial 122 finished with value: 60387.48736950025 and parameters: {'alpha': 17.563049509160365, 'fit_intercept': False, 'tol': 0.13884795015239812, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,142] Trial 123 finished with value: 63616.40139391284 and parameters: {'alpha': 21.784862014345418, 'fit_intercept': False, 'tol': 0.10356613649885484, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,194] Trial 124 finished with value: 60316.87207226751 and parameters: {'alpha': 10.413628383542417, 'fit_intercept': False, 'tol': 0.0867738267611443, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,215] Trial 125 finished with value: 60922.349863073934 and parameters: {'alpha': 24.231218817164066, 'fit_intercept': False, 'tol': 0.17662437425982497, 'solver': 'cholesky'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,263] Trial 126 finished with value: 60474.788493509535 and parameters: {'alpha': 16.8246884833871, 'fit_intercept': False, 'tol': 0.1122472112766237, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,299] Trial 127 finished with value: 60885.582348078584 and parameters: {'alpha': 18.668888904974505, 'fit_intercept': False, 'tol': 0.09206135203460124, 'solver': 'svd'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,356] Trial 128 finished with value: 61541.06986838517 and parameters: {'alpha': 20.34058883310419, 'fit_intercept': False, 'tol': 0.07302716315130058, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,405] Trial 129 finished with value: 64358.85469478189 and parameters: {'alpha': 13.427570949155704, 'fit_intercept': False, 'tol': 0.14682535774766975, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,465] Trial 130 finished with value: 59818.47825466597 and parameters: {'alpha': 8.736246026430123, 'fit_intercept': False, 'tol': 0.04410209222311569, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,540] Trial 131 finished with value: 60655.40180994665 and parameters: {'alpha': 8.790230713121193, 'fit_intercept': False, 'tol': 0.04563496256226504, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,600] Trial 132 finished with value: 60623.889573418935 and parameters: {'alpha': 11.563661055097779, 'fit_intercept': False, 'tol': 0.058536678318134965, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,643] Trial 133 finished with value: 59435.80723506874 and parameters: {'alpha': 6.08487131528575, 'fit_intercept': False, 'tol': 0.20595116921010362, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,663] Trial 134 finished with value: 60780.041064533405 and parameters: {'alpha': 3.9562577537342047, 'fit_intercept': False, 'tol': 0.23955945782793844, 'solver': 'auto'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,706] Trial 135 finished with value: 62236.92733079063 and parameters: {'alpha': 6.029119774418916, 'fit_intercept': False, 'tol': 0.1953851292969226, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,747] Trial 136 finished with value: 61939.13227635213 and parameters: {'alpha': 2.0434361570092188, 'fit_intercept': False, 'tol': 0.3076370127934664, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,794] Trial 137 finished with value: 60734.058933032466 and parameters: {'alpha': 6.936717703156183, 'fit_intercept': False, 'tol': 0.23562524207749888, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,839] Trial 138 finished with value: 62491.36089376647 and parameters: {'alpha': 4.5235665291492815, 'fit_intercept': False, 'tol': 0.12603764103167425, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,875] Trial 139 finished with value: 58823.3397724667 and parameters: {'alpha': 9.544734754298899, 'fit_intercept': False, 'tol': 0.37851597684983046, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,910] Trial 140 finished with value: 93106.68412133954 and parameters: {'alpha': 9.227641792940886, 'fit_intercept': False, 'tol': 0.3806174357694596, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,947] Trial 141 finished with value: 61233.20397626172 and parameters: {'alpha': 15.223176961339234, 'fit_intercept': False, 'tol': 0.3627350300530469, 'solver': 'saga'}. Best is trial 84 with value: 56764.61633316871.\n",
      "[I 2023-09-01 13:30:10,991] Trial 142 finished with value: 56197.479563237925 and parameters: {'alpha': 10.16686629792529, 'fit_intercept': False, 'tol': 0.20448130680388094, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,034] Trial 143 finished with value: 59549.163012488985 and parameters: {'alpha': 9.998460260444338, 'fit_intercept': False, 'tol': 0.20798213766825635, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,077] Trial 144 finished with value: 58155.095826670426 and parameters: {'alpha': 10.08652829051945, 'fit_intercept': False, 'tol': 0.16857504895466036, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,122] Trial 145 finished with value: 59110.90208586313 and parameters: {'alpha': 11.486140628279163, 'fit_intercept': False, 'tol': 0.20502295575285578, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,161] Trial 146 finished with value: 65138.65422385218 and parameters: {'alpha': 12.53247123106133, 'fit_intercept': False, 'tol': 0.2500715104310498, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,209] Trial 147 finished with value: 61190.33093434396 and parameters: {'alpha': 11.759527815729129, 'fit_intercept': True, 'tol': 0.2045647108828564, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,253] Trial 148 finished with value: 59301.268132439494 and parameters: {'alpha': 10.23747777929943, 'fit_intercept': False, 'tol': 0.1692289449264726, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,275] Trial 149 finished with value: 67304.00535088284 and parameters: {'alpha': 10.212061993963072, 'fit_intercept': False, 'tol': 0.21189580098091196, 'solver': 'lsqr'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,318] Trial 150 finished with value: 60137.93373119573 and parameters: {'alpha': 14.985926425148152, 'fit_intercept': False, 'tol': 0.1692717712728219, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,360] Trial 151 finished with value: 61151.29598810857 and parameters: {'alpha': 13.569126445680334, 'fit_intercept': False, 'tol': 0.17956659760222685, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,401] Trial 152 finished with value: 59852.409282113906 and parameters: {'alpha': 10.132804887530677, 'fit_intercept': False, 'tol': 0.23805489245852687, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,446] Trial 153 finished with value: 59158.11922829233 and parameters: {'alpha': 7.460221021126381, 'fit_intercept': False, 'tol': 0.1954644816252397, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,489] Trial 154 finished with value: 61070.7920153507 and parameters: {'alpha': 6.365375563203186, 'fit_intercept': False, 'tol': 0.19915782779504906, 'solver': 'saga'}. Best is trial 142 with value: 56197.479563237925.\n",
      "[I 2023-09-01 13:30:11,533] Trial 155 finished with value: 53957.22921136447 and parameters: {'alpha': 7.985580527818927, 'fit_intercept': False, 'tol': 0.2598657519653165, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,586] Trial 156 finished with value: 54063.14559177048 and parameters: {'alpha': 7.583225396801234, 'fit_intercept': False, 'tol': 0.26203929425716094, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,639] Trial 157 finished with value: 65127.906328618476 and parameters: {'alpha': 7.844217942308913, 'fit_intercept': False, 'tol': 0.269072487787962, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,689] Trial 158 finished with value: 68602.94876246578 and parameters: {'alpha': 7.841736673212284, 'fit_intercept': False, 'tol': 0.319674957155962, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,756] Trial 159 finished with value: 66738.22264554827 and parameters: {'alpha': 2.075063190470674, 'fit_intercept': False, 'tol': 0.25749182124230263, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,807] Trial 160 finished with value: 63773.465285787584 and parameters: {'alpha': 11.117137266021098, 'fit_intercept': False, 'tol': 0.1739250387254359, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,838] Trial 161 finished with value: 60822.64600049463 and parameters: {'alpha': 9.77115738243994, 'fit_intercept': False, 'tol': 0.23422197920877486, 'solver': 'svd'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,859] Trial 162 finished with value: 60806.20283075672 and parameters: {'alpha': 7.533788057688545, 'fit_intercept': False, 'tol': 0.21162417203161896, 'solver': 'cholesky'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,901] Trial 163 finished with value: 61910.39323674217 and parameters: {'alpha': 12.154409413894177, 'fit_intercept': False, 'tol': 0.29570253782972467, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:11,968] Trial 164 finished with value: 58975.649976551395 and parameters: {'alpha': 4.762514233287142, 'fit_intercept': False, 'tol': 0.18203702441283123, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,033] Trial 165 finished with value: 60294.77255513728 and parameters: {'alpha': 3.6298006791046635, 'fit_intercept': False, 'tol': 0.16950777545379853, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,086] Trial 166 finished with value: 77117.03401895388 and parameters: {'alpha': 4.977968499262344, 'fit_intercept': False, 'tol': 0.3217184090792579, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,133] Trial 167 finished with value: 65089.08637294115 and parameters: {'alpha': 15.748109540943059, 'fit_intercept': False, 'tol': 0.24914391750934742, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,196] Trial 168 finished with value: 62642.94193237092 and parameters: {'alpha': 7.27062382082196, 'fit_intercept': False, 'tol': 0.152498923886958, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,217] Trial 169 finished with value: 60755.69073226593 and parameters: {'alpha': 0.4877066031805857, 'fit_intercept': False, 'tol': 0.18977694680448046, 'solver': 'auto'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,259] Trial 170 finished with value: 60944.00544091555 and parameters: {'alpha': 13.735703900282328, 'fit_intercept': True, 'tol': 0.42583934964121944, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,302] Trial 171 finished with value: 60395.28015687273 and parameters: {'alpha': 9.340731239975838, 'fit_intercept': False, 'tol': 0.21026540370478788, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,345] Trial 172 finished with value: 61021.21682173413 and parameters: {'alpha': 10.78627878426461, 'fit_intercept': False, 'tol': 0.21349553909778515, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,388] Trial 173 finished with value: 62347.42732933051 and parameters: {'alpha': 6.121991138382928, 'fit_intercept': False, 'tol': 0.1782720811802467, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,431] Trial 174 finished with value: 59220.60307815952 and parameters: {'alpha': 8.888759872055365, 'fit_intercept': False, 'tol': 0.2797294658492092, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,469] Trial 175 finished with value: 60561.46884487056 and parameters: {'alpha': 3.184051337464645, 'fit_intercept': False, 'tol': 0.2771774898606732, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,512] Trial 176 finished with value: 66846.23613619407 and parameters: {'alpha': 8.376199315792848, 'fit_intercept': False, 'tol': 0.5472814406339092, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,561] Trial 177 finished with value: 62303.029331192716 and parameters: {'alpha': 17.09582004027273, 'fit_intercept': False, 'tol': 0.14064509661164984, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,601] Trial 178 finished with value: 59942.96883050012 and parameters: {'alpha': 12.58098276064968, 'fit_intercept': False, 'tol': 0.2530129775982045, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,643] Trial 179 finished with value: 58329.51171472987 and parameters: {'alpha': 5.648356161137084, 'fit_intercept': False, 'tol': 0.31738851109000044, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,684] Trial 180 finished with value: 63662.40606993469 and parameters: {'alpha': 5.33013920472481, 'fit_intercept': False, 'tol': 0.330303301040683, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,725] Trial 181 finished with value: 59983.97570119887 and parameters: {'alpha': 7.515546895496914, 'fit_intercept': False, 'tol': 0.2878779912338559, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,764] Trial 182 finished with value: 69392.84422011819 and parameters: {'alpha': 2.850115640874499, 'fit_intercept': False, 'tol': 0.3728855278311551, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,805] Trial 183 finished with value: 57396.405122713724 and parameters: {'alpha': 11.209473109196793, 'fit_intercept': False, 'tol': 0.23295600811986938, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,848] Trial 184 finished with value: 60655.98283922359 and parameters: {'alpha': 54.867826340811845, 'fit_intercept': False, 'tol': 0.22787629693807773, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,889] Trial 185 finished with value: 64541.30218238355 and parameters: {'alpha': 12.292485270723738, 'fit_intercept': False, 'tol': 0.283093962585209, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,945] Trial 186 finished with value: 61293.29463797799 and parameters: {'alpha': 4.5105814033384055, 'fit_intercept': False, 'tol': 0.3404415822072432, 'solver': 'sag'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:12,990] Trial 187 finished with value: 62827.698960851805 and parameters: {'alpha': 14.771314808232507, 'fit_intercept': False, 'tol': 0.18368765420605448, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,012] Trial 188 finished with value: 67306.39048930716 and parameters: {'alpha': 8.772100288735524, 'fit_intercept': False, 'tol': 0.24661729881581182, 'solver': 'lsqr'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,057] Trial 189 finished with value: 63926.99148775926 and parameters: {'alpha': 6.891550866435165, 'fit_intercept': False, 'tol': 0.19322826067490156, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,106] Trial 190 finished with value: 60223.19048914696 and parameters: {'alpha': 10.308220516922153, 'fit_intercept': False, 'tol': 0.1641582151765498, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,148] Trial 191 finished with value: 63433.17955146653 and parameters: {'alpha': 13.863565182352483, 'fit_intercept': False, 'tol': 0.23060196118336976, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,196] Trial 192 finished with value: 61535.07047029573 and parameters: {'alpha': 40.82014054386781, 'fit_intercept': False, 'tol': 0.1558279250775128, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,247] Trial 193 finished with value: 54479.7393862191 and parameters: {'alpha': 11.381795124578636, 'fit_intercept': False, 'tol': 0.38976046276728293, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,293] Trial 194 finished with value: 59316.84188375319 and parameters: {'alpha': 16.641874110512905, 'fit_intercept': False, 'tol': 0.37950793356308393, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,332] Trial 195 finished with value: 61880.69892884015 and parameters: {'alpha': 10.894662550832647, 'fit_intercept': False, 'tol': 0.3901898001237562, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,372] Trial 196 finished with value: 57132.082216601404 and parameters: {'alpha': 8.74243337921714, 'fit_intercept': False, 'tol': 0.4081893487647497, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,407] Trial 197 finished with value: 61580.55432448202 and parameters: {'alpha': 16.80272048696638, 'fit_intercept': False, 'tol': 0.44010620486869256, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,452] Trial 198 finished with value: 57479.77612422298 and parameters: {'alpha': 11.974243501183143, 'fit_intercept': False, 'tol': 0.5083439851458538, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n",
      "[I 2023-09-01 13:30:13,504] Trial 199 finished with value: 62468.360492647436 and parameters: {'alpha': 9.079169328009765, 'fit_intercept': False, 'tol': 0.5295631616328342, 'solver': 'saga'}. Best is trial 155 with value: 53957.22921136447.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_r2</th>\n",
       "      <th>mean_MAPE</th>\n",
       "      <th>mean_MSE</th>\n",
       "      <th>std_r2</th>\n",
       "      <th>std_MAPE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>score</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.01427</td>\n",
       "      <td>2.605928</td>\n",
       "      <td>21309.386152</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.250713</td>\n",
       "      <td>1767.610818</td>\n",
       "      <td>5</td>\n",
       "      <td>54738.318896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_r2  mean_MAPE      mean_MSE   std_r2  std_MAPE      std_MSE  score   \n",
       "155  0.01427   2.605928  21309.386152  0.00753  0.250713  1767.610818      5  \\\n",
       "\n",
       "     combined_score  \n",
       "155    54738.318896  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_optimization(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.52004583332408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(12886.800806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegressor_optimization(number_of_trials):\n",
    "    # input to study should be dataset and number of iterations\n",
    "    eval_metrics_dictionary = {'mean_r2':[],'mean_MAPE':[],'mean_MSE':[],'std_r2':[],'std_MAPE':[],'std_MSE':[],'score':[]}\n",
    "    randoforreg_dictionary = {\n",
    "        'n_estimators': [], \n",
    "        'max_depth': [],\n",
    "        'min_samples_split': [],\n",
    "        'min_samples_leaf':[]\n",
    "        }\n",
    "\n",
    "    def objective(trial):\n",
    "        ## HYPER PARAMETER TUNING\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 300, log=True)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "        # Create and fit random forest model\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42,\n",
    "            )\n",
    "        model.fit(ridge_Xtrain, y_train)\n",
    "        \n",
    "        # Function parameters for cross_val_score; \n",
    "        #   - estimator - The model object to use to fit the data\n",
    "        #   - X - The data to fit the model on\n",
    "        #   - y - The target of the model\n",
    "        #   - scoring - The error metric to use\n",
    "        #   - cv - The number of splits to use\n",
    "        \n",
    "        # error score to use; \n",
    "        #   - accuracy\n",
    "        #   - balanced_accuracy\n",
    "        #   - roc_auc\n",
    "        #   - f1\n",
    "        #   - neg_mean_absolute_error\n",
    "        #   - neg_root_mean_squared_error\n",
    "        #   - r2\n",
    "        \n",
    "        ## EVALUATION METRICS\n",
    "        # you should really use cross_val_score rather than testing against the test set\n",
    "        score = cross_validate(model, ridge_Xtrain, y_train, scoring=('neg_mean_absolute_percentage_error', 'r2', 'neg_mean_squared_error'), cv=3)\n",
    "        mean_MAPE = -1*np.mean(score['test_neg_mean_absolute_percentage_error'])\n",
    "        mean_r2 = np.mean(score['test_r2'])\n",
    "        mean_MSE = -1*np.mean(score['test_neg_mean_squared_error'])\n",
    "        std_MAPE = np.std(score['test_neg_mean_absolute_percentage_error'])\n",
    "        std_r2 = np.std(score['test_r2'])\n",
    "        std_MSE = np.std(score['test_neg_mean_squared_error'])\n",
    "        \n",
    "        \"\"\"\n",
    "        y_pred_train= ridge_regressor.predict(X_test)\n",
    "            \n",
    "        Evaluation metrics;\n",
    "        - R squared\n",
    "        - MSE\n",
    "        - RMSE\n",
    "        - MAPE\n",
    "        \n",
    "        infun_MSE = mean_squared_error(y_test,y_pred_train)\n",
    "        infun_RMSE = math.sqrt(infun_MSE)\n",
    "        infun_r2 = r2_score(y_test, y_pred_train) \n",
    "        infun_MAPE = mean_absolute_percentage_error(y_test, y_pred_train) \n",
    "        max_coeff = ridge_regressor.coef_.round(3)\n",
    "        eval_metrics_dictionary['r2'].append(infun_r2)\n",
    "        eval_metrics_dictionary['MSE'].append(infun_MSE)\n",
    "        eval_metrics_dictionary['RMSE'].append(infun_RMSE)\n",
    "        eval_metrics_dictionary['MAPE'].append(infun_MAPE)\n",
    "        \"\"\"\n",
    "        #coeff_used = np.sum(model.coef_!=0)\n",
    "\n",
    "        eval_metrics_dictionary['mean_MAPE'].append(mean_MAPE)\n",
    "        eval_metrics_dictionary['mean_r2'].append(mean_r2)\n",
    "        eval_metrics_dictionary['mean_MSE'].append(mean_MSE)\n",
    "        eval_metrics_dictionary['std_MAPE'].append(std_MAPE)\n",
    "        eval_metrics_dictionary['std_r2'].append(std_r2)\n",
    "        eval_metrics_dictionary['std_MSE'].append(std_MSE)\n",
    "        eval_metrics_dictionary['score'].append(len(score))\n",
    "        \n",
    "        randoforreg_dictionary['n_estimators'].append(n_estimators)\n",
    "        randoforreg_dictionary['max_depth'].append(max_depth)\n",
    "        randoforreg_dictionary['min_samples_split'].append(min_samples_split)\n",
    "        randoforreg_dictionary['min_samples_leaf'].append(min_samples_leaf)\n",
    "        #randoforreg_dictionary['no_of_coefficients'].append(coeff_used)\n",
    "\n",
    "        return mean_MSE*mean_MAPE*(1-mean_r2)*(1-mean_r2)\n",
    "        #return mean_MSE\n",
    "\n",
    "    study2 = optuna.create_study(study_name=\"RandomForestRegression Optimization\")\n",
    "    study2.optimize(objective, n_trials=number_of_trials)\n",
    "    df_framework = pd.DataFrame(eval_metrics_dictionary)\n",
    "    # * by the r2_score that is closest to 1 --- you want to minimise the values of the rest, dont need to include RMSE, you overweight that value\n",
    "    df_framework['combined_score'] = abs(abs(1 - df_framework['mean_r2'])*df_framework['mean_MSE']*df_framework['mean_MAPE'])\n",
    "    df_bestvalue = df_framework[df_framework['combined_score']==min(df_framework['combined_score'])]\n",
    "    return df_bestvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-01 13:30:13,542] A new study created in memory with name: RandomForestRegression Optimization\n",
      "[I 2023-09-01 13:30:29,581] Trial 0 finished with value: 51741.532991626074 and parameters: {'n_estimators': 157, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 51741.532991626074.\n",
      "[I 2023-09-01 13:30:31,154] Trial 1 finished with value: 51187.44808971352 and parameters: {'n_estimators': 12, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 1 with value: 51187.44808971352.\n",
      "[I 2023-09-01 13:30:37,132] Trial 2 finished with value: 54782.58277697465 and parameters: {'n_estimators': 37, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 51187.44808971352.\n",
      "[I 2023-09-01 13:30:41,279] Trial 3 finished with value: 49179.0413339604 and parameters: {'n_estimators': 35, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 3 with value: 49179.0413339604.\n",
      "[I 2023-09-01 13:30:42,782] Trial 4 finished with value: 51554.974263373624 and parameters: {'n_estimators': 13, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 3 with value: 49179.0413339604.\n",
      "[I 2023-09-01 13:30:48,314] Trial 5 finished with value: 52999.38993110981 and parameters: {'n_estimators': 40, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 49179.0413339604.\n",
      "[I 2023-09-01 13:30:48,583] Trial 6 finished with value: 61121.387788068656 and parameters: {'n_estimators': 12, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 49179.0413339604.\n",
      "[I 2023-09-01 13:30:59,535] Trial 7 finished with value: 48425.29281267423 and parameters: {'n_estimators': 83, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 7 with value: 48425.29281267423.\n",
      "[I 2023-09-01 13:31:04,494] Trial 8 finished with value: 50459.973480975204 and parameters: {'n_estimators': 35, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 7 with value: 48425.29281267423.\n",
      "[I 2023-09-01 13:31:09,812] Trial 9 finished with value: 49859.20578224662 and parameters: {'n_estimators': 50, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 7 with value: 48425.29281267423.\n",
      "[I 2023-09-01 13:31:32,752] Trial 10 finished with value: 47952.4996830488 and parameters: {'n_estimators': 179, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 10 with value: 47952.4996830488.\n",
      "[I 2023-09-01 13:31:59,289] Trial 11 finished with value: 47863.545521019754 and parameters: {'n_estimators': 198, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 11 with value: 47863.545521019754.\n",
      "[I 2023-09-01 13:32:38,158] Trial 12 finished with value: 47839.82903446819 and parameters: {'n_estimators': 294, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 12 with value: 47839.82903446819.\n",
      "[I 2023-09-01 13:33:19,745] Trial 13 finished with value: 47836.05989572654 and parameters: {'n_estimators': 298, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 13 with value: 47836.05989572654.\n",
      "[I 2023-09-01 13:33:57,981] Trial 14 finished with value: 48099.75571955203 and parameters: {'n_estimators': 267, 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 13 with value: 47836.05989572654.\n",
      "[I 2023-09-01 13:34:42,907] Trial 15 finished with value: 49382.08355833198 and parameters: {'n_estimators': 294, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 13 with value: 47836.05989572654.\n",
      "[I 2023-09-01 13:34:59,319] Trial 16 finished with value: 47944.99887441628 and parameters: {'n_estimators': 124, 'max_depth': 32, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 13 with value: 47836.05989572654.\n",
      "[I 2023-09-01 13:35:34,967] Trial 17 finished with value: 47837.43402155656 and parameters: {'n_estimators': 289, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 13 with value: 47836.05989572654.\n",
      "[I 2023-09-01 13:35:59,827] Trial 18 finished with value: 47830.8016301563 and parameters: {'n_estimators': 204, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 18 with value: 47830.8016301563.\n",
      "[I 2023-09-01 13:36:13,306] Trial 19 finished with value: 48334.3598259203 and parameters: {'n_estimators': 102, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 18 with value: 47830.8016301563.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_r2</th>\n",
       "      <th>mean_MAPE</th>\n",
       "      <th>mean_MSE</th>\n",
       "      <th>std_r2</th>\n",
       "      <th>std_MAPE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>score</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.061617</td>\n",
       "      <td>2.677337</td>\n",
       "      <td>20290.476753</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.111082</td>\n",
       "      <td>1723.892907</td>\n",
       "      <td>5</td>\n",
       "      <td>50977.126178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_r2  mean_MAPE      mean_MSE    std_r2  std_MAPE      std_MSE  score   \n",
       "13  0.061617   2.677337  20290.476753  0.009114  0.111082  1723.892907      5  \\\n",
       "\n",
       "    combined_score  \n",
       "13    50977.126178  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor_optimization(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11989.482402"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11989.482402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.49649493020313"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(11989.482402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SVRegressor_optimization(number_of_trials):\n",
    "    # input to study should be dataset and number of iterations\n",
    "    eval_metrics_dictionary = {'mean_r2':[],'mean_MAPE':[],'mean_MSE':[],'std_r2':[],'std_MAPE':[],'std_MSE':[],'score':[]}\n",
    "    SVRegressor_dictionary ={\n",
    "        'kernel' :[],\n",
    "        'C' :[],\n",
    "        'degree' :[],\n",
    "        'coef0' :[],\n",
    "        'gamma' :[]\n",
    "    }\n",
    "    def objective(trial):\n",
    "        ## HYPER PARAMETER TUNING\n",
    "        degree = trial.suggest_int(\"degree\", 3, 8)\n",
    "        C = trial.suggest_int(\"C\", 1, 10)\n",
    "        coef0 = trial.suggest_float(\"coef0\", 0.01, 10)\n",
    "        gamma = trial.suggest_categorical(\"gamma\", [\"auto\", 'scale'])\n",
    "        kernel = trial.suggest_categorical(\"kernel\", ['poly'])\n",
    "        # ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "\n",
    "\n",
    "        # Create and fit random forest model\n",
    "        model = SVR(\n",
    "            kernel=kernel,\n",
    "            C=C,\n",
    "            degree=degree,\n",
    "            coef0=coef0,\n",
    "            gamma=gamma,\n",
    "            )\n",
    "        model.fit(ridge_Xtrain, y_train)\n",
    "        \n",
    "        # Function parameters for cross_val_score; \n",
    "        #   - estimator - The model object to use to fit the data\n",
    "        #   - X - The data to fit the model on\n",
    "        #   - y - The target of the model\n",
    "        #   - scoring - The error metric to use\n",
    "        #   - cv - The number of splits to use\n",
    "        \n",
    "        # error score to use; \n",
    "        #   - accuracy\n",
    "        #   - balanced_accuracy\n",
    "        #   - roc_auc\n",
    "        #   - f1\n",
    "        #   - neg_mean_absolute_error\n",
    "        #   - neg_root_mean_squared_error\n",
    "        #   - r2\n",
    "        \n",
    "        ## EVALUATION METRICS\n",
    "        # you should really use cross_val_score rather than testing against the test set\n",
    "        score = cross_validate(model, ridge_Xtrain, y_train, scoring=('neg_mean_absolute_percentage_error', 'r2', 'neg_mean_squared_error'), cv=3)\n",
    "        mean_MAPE = -1*np.mean(score['test_neg_mean_absolute_percentage_error'])\n",
    "        mean_r2 = np.mean(score['test_r2'])\n",
    "        mean_MSE = -1*np.mean(score['test_neg_mean_squared_error'])\n",
    "        std_MAPE = np.std(score['test_neg_mean_absolute_percentage_error'])\n",
    "        std_r2 = np.std(score['test_r2'])\n",
    "        std_MSE = np.std(score['test_neg_mean_squared_error'])\n",
    "        \n",
    "        \"\"\"\n",
    "        y_pred_train= ridge_regressor.predict(X_test)\n",
    "            \n",
    "        Evaluation metrics;\n",
    "        - R squared\n",
    "        - MSE\n",
    "        - RMSE\n",
    "        - MAPE\n",
    "        \n",
    "        infun_MSE = mean_squared_error(y_test,y_pred_train)\n",
    "        infun_RMSE = math.sqrt(infun_MSE)\n",
    "        infun_r2 = r2_score(y_test, y_pred_train) \n",
    "        infun_MAPE = mean_absolute_percentage_error(y_test, y_pred_train) \n",
    "        max_coeff = ridge_regressor.coef_.round(3)\n",
    "        eval_metrics_dictionary['r2'].append(infun_r2)\n",
    "        eval_metrics_dictionary['MSE'].append(infun_MSE)\n",
    "        eval_metrics_dictionary['RMSE'].append(infun_RMSE)\n",
    "        eval_metrics_dictionary['MAPE'].append(infun_MAPE)\n",
    "        \"\"\"\n",
    "        #coeff_used = np.sum(model.coef_!=0)\n",
    "\n",
    "        eval_metrics_dictionary['mean_MAPE'].append(mean_MAPE)\n",
    "        eval_metrics_dictionary['mean_r2'].append(mean_r2)\n",
    "        eval_metrics_dictionary['mean_MSE'].append(mean_MSE)\n",
    "        eval_metrics_dictionary['std_MAPE'].append(std_MAPE)\n",
    "        eval_metrics_dictionary['std_r2'].append(std_r2)\n",
    "        eval_metrics_dictionary['std_MSE'].append(std_MSE)\n",
    "        eval_metrics_dictionary['score'].append(len(score))\n",
    "        \n",
    "        SVRegressor_dictionary['degree'].append(degree)\n",
    "        SVRegressor_dictionary['C'].append(C)\n",
    "        SVRegressor_dictionary['coef0'].append(coef0)\n",
    "        SVRegressor_dictionary['gamma'].append(gamma)\n",
    "        SVRegressor_dictionary['kernel'].append(kernel)\n",
    "        #randoforreg_dictionary['no_of_coefficients'].append(coeff_used)\n",
    "        #return mean_MSE*mean_MAPE*(1-mean_r2)*(1-mean_r2)\n",
    "        return mean_MSE\n",
    "\n",
    "    study2 = optuna.create_study(study_name=\"SVRRegression Optimization\")\n",
    "    study2.optimize(objective, n_trials=number_of_trials)\n",
    "    df_framework = pd.DataFrame(eval_metrics_dictionary)\n",
    "    # * by the r2_score that is closest to 1 --- you want to minimise the values of the rest, dont need to include RMSE, you overweight that value\n",
    "    df_framework['combined_score'] = abs(abs(1 - df_framework['mean_r2'])*df_framework['mean_MSE']*df_framework['mean_MAPE'])\n",
    "    df_bestvalue = df_framework[df_framework['combined_score']==min(df_framework['combined_score'])]\n",
    "    return df_bestvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-01 13:36:13,395] A new study created in memory with name: SVRRegression Optimization\n"
     ]
    }
   ],
   "source": [
    "## when c == degreee it looks v good\n",
    "SVRegressor_optimization(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeRegressor_optimization(number_of_trials):\n",
    "    # input to study should be dataset and number of iterations\n",
    "    eval_metrics_dictionary = {'mean_r2':[],'mean_MAPE':[],'mean_MSE':[],'std_r2':[],'std_MAPE':[],'std_MSE':[],'score':[]}\n",
    "    dectrereg_dictionary = {'max_depth': [], 'min_samples_split': [],'min_samples_leaf': [],'random_state':[]}\n",
    "\n",
    "    def objective(trial):\n",
    "        ## HYPER PARAMETER TUNING\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "        random_state = trial.suggest_int(\"random_state\", 0, 50)\n",
    "\n",
    "        # Create and fit random forest model\n",
    "        model = DecisionTreeRegressor(\n",
    "                max_depth=max_depth,\n",
    "                min_samples_leaf=min_samples_leaf, \n",
    "                min_samples_split=min_samples_split,\n",
    "                random_state=random_state\n",
    "                )\n",
    "        model.fit(ridge_Xtrain, y_train)\n",
    "        \n",
    "        # Function parameters for cross_val_score; \n",
    "        #   - estimator - The model object to use to fit the data\n",
    "        #   - X - The data to fit the model on\n",
    "        #   - y - The target of the model\n",
    "        #   - scoring - The error metric to use\n",
    "        #   - cv - The number of splits to use\n",
    "        \n",
    "        # error score to use; \n",
    "        #   - accuracy\n",
    "        #   - balanced_accuracy\n",
    "        #   - roc_auc\n",
    "        #   - f1\n",
    "        #   - neg_mean_absolute_error\n",
    "        #   - neg_root_mean_squared_error\n",
    "        #   - r2\n",
    "        \n",
    "        ## EVALUATION METRICS\n",
    "        # you should really use cross_val_score rather than testing against the test set\n",
    "        score = cross_validate(model, ridge_Xtrain, y_train, scoring=('neg_mean_absolute_percentage_error', 'r2', 'neg_mean_squared_error'), cv=3)\n",
    "        mean_MAPE = -1*np.mean(score['test_neg_mean_absolute_percentage_error'])\n",
    "        mean_r2 = np.mean(score['test_r2'])\n",
    "        mean_MSE = -1*np.mean(score['test_neg_mean_squared_error'])\n",
    "        std_MAPE = np.std(score['test_neg_mean_absolute_percentage_error'])\n",
    "        std_r2 = np.std(score['test_r2'])\n",
    "        std_MSE = np.std(score['test_neg_mean_squared_error'])\n",
    "        \n",
    "        \"\"\"\n",
    "        y_pred_train= ridge_regressor.predict(X_test)\n",
    "            \n",
    "        Evaluation metrics;\n",
    "        - R squared\n",
    "        - MSE\n",
    "        - RMSE\n",
    "        - MAPE\n",
    "        \n",
    "        infun_MSE = mean_squared_error(y_test,y_pred_train)\n",
    "        infun_RMSE = math.sqrt(infun_MSE)\n",
    "        infun_r2 = r2_score(y_test, y_pred_train) \n",
    "        infun_MAPE = mean_absolute_percentage_error(y_test, y_pred_train) \n",
    "        max_coeff = ridge_regressor.coef_.round(3)\n",
    "        eval_metrics_dictionary['r2'].append(infun_r2)\n",
    "        eval_metrics_dictionary['MSE'].append(infun_MSE)\n",
    "        eval_metrics_dictionary['RMSE'].append(infun_RMSE)\n",
    "        eval_metrics_dictionary['MAPE'].append(infun_MAPE)\n",
    "        \"\"\"\n",
    "        #coeff_used = np.sum(model.coef_!=0)\n",
    "\n",
    "        eval_metrics_dictionary['mean_MAPE'].append(mean_MAPE)\n",
    "        eval_metrics_dictionary['mean_r2'].append(mean_r2)\n",
    "        eval_metrics_dictionary['mean_MSE'].append(mean_MSE)\n",
    "        eval_metrics_dictionary['std_MAPE'].append(std_MAPE)\n",
    "        eval_metrics_dictionary['std_r2'].append(std_r2)\n",
    "        eval_metrics_dictionary['std_MSE'].append(std_MSE)\n",
    "        eval_metrics_dictionary['score'].append(len(score))\n",
    "        \n",
    "        dectrereg_dictionary['max_depth'].append(max_depth)\n",
    "        dectrereg_dictionary['min_samples_split'].append(min_samples_split)\n",
    "        dectrereg_dictionary['min_samples_leaf'].append(min_samples_leaf)\n",
    "        dectrereg_dictionary['random_state'].append(random_state)\n",
    "        #randoforreg_dictionary['no_of_coefficients'].append(coeff_used)\n",
    "\n",
    "        return mean_MSE*mean_MAPE*(1-mean_r2)*(1-mean_r2)\n",
    "        #return mean_MSE\n",
    "\n",
    "    study2 = optuna.create_study(study_name=\"DecisionTreeRegressor Optimization\")\n",
    "    study2.optimize(objective, n_trials=number_of_trials)\n",
    "    df_framework = pd.DataFrame(eval_metrics_dictionary)\n",
    "    # * by the r2_score that is closest to 1 --- you want to minimise the values of the rest, dont need to include RMSE, you overweight that value\n",
    "    df_framework['combined_score'] = abs(abs(1 - df_framework['mean_r2'])*df_framework['mean_MSE']*df_framework['mean_MAPE'])\n",
    "    df_bestvalue = df_framework[df_framework['combined_score']==min(df_framework['combined_score'])]\n",
    "    return df_bestvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor_optimization(200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
